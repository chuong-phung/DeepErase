{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: old comet version (1.0.44) detected. current: 1.0.53 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
      "COMET WARNING: Failing to collect the installed os packages\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/yikeqicn/segnet/f198089f14974221b181056ef537ac62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "from comet_ml import Experiment\n",
    "experiment = Experiment(api_key=\"YkPEmantOag1R1VOJmXz11hmt\", parse_args=False, project_name='SegNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, basename, dirname\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from torch.utils.data import DataLoader, ConcatDataset, random_split#, SequentialSampler #yike: add SequentialSampler\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from datasets import IRS #ArtPrintNoIntsectLBW,ArtPrintNoIntsectLBW_biameyd_siameyd,ArtPrintNoIntsectLBW_bpr_spr,ArtPrintNoIntsectLBW_biameyd_sprt\n",
    "from Model_Unet_github import *\n",
    "\n",
    "home = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General Settings\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# system basics\n",
    "parser.add_argument(\"-name\", default='segnet_unet_lbw_all_combine_100_epoches', type=str, help=\"name of the log\") #debug model_intersect # segnet_no_intersect_1conv_64_channels_30epoch_unet_github\n",
    "parser.add_argument(\"-gpu\", default='1', type=str, help=\"gpu numbers\")\n",
    "\n",
    "parser.add_argument(\"-train\", default=False, help=\"train the NN\", action=\"store_true\")\n",
    "\n",
    "parser.add_argument(\"-transfer\",default=False, help=\"test the NN\", action=\"store_true\")\n",
    "\n",
    "parser.add_argument(\"-test\",default=True, help=\"test the NN\", action=\"store_true\")\n",
    "\n",
    "# image and logistic parameters \n",
    "parser.add_argument(\"-image_h\", default=32, type=int, help='image height') #('image_h', \"360\", \"\"\" image height \"\"\") 32\n",
    "parser.add_argument(\"-image_w\", default=128, type=int, help='image width')#('image_w', \"480\", \"\"\" image width \"\"\")128\n",
    "#parser.add_argument(\"-image_h\", default=360, type=int, help='image height') \n",
    "#parser.add_argument(\"-image_w\", default=480, type=int, help='image width')\n",
    "\n",
    "parser.add_argument(\"-image_c\", default=1, type=int, help='image channel')#('image_c', \"3\", \"\"\" image channel (RGB) \"\"\")\n",
    "parser.add_argument(\"-num_class\", default=2, type=int, help='total class number')\n",
    "\n",
    "# training hyperparam\n",
    "parser.add_argument(\"-batch_size\", default=10, type=int, help='batch_size')\n",
    "parser.add_argument(\"-lrInit\", default=1e-3, type=int, help='initial lr')\n",
    "parser.add_argument(\"-lrDrop1\", default=10, type=int, help='step to drop lr by 10 first time') # not sure\n",
    "parser.add_argument(\"-lrDrop2\", default=1000, type=int, help='step to drop lr by 10 sexond time') # not sure\n",
    "parser.add_argument('-max_epoch',default=100, type=int,help='max epoch numbers')\n",
    "\n",
    "\n",
    "\n",
    "# file paths\n",
    "parser.add_argument('-ckpt_root', default=\"/root/ckpt\", type=str,help= \"dir to store ckpt\") # log_dir !!!!!\n",
    "parser.add_argument('-data_root', default=\"/root/datasets\", type=str, help=\" root to any data folder \")\n",
    "parser.add_argument('-urlTranferFrom', default=\"\", type=str, help=\" archived model url \")\n",
    "\n",
    "\n",
    "#args = parser.parse_args()\n",
    "args = parser.parse_known_args()[0]\n",
    "\n",
    "name = args.name\n",
    "\n",
    "experiment.set_name('segnet_unet_lbw_all_test_irs_handwriting')\n",
    "experiment.log_parameters(vars(args))\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "\n",
    "ckptroot = args.ckpt_root\n",
    "args.ckptpath = join(ckptroot, name)\n",
    "if args.name=='debug': shutil.rmtree(args.ckptpath, ignore_errors=True)\n",
    "os.makedirs(args.ckptpath, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def checkArgs():\n",
    "    if args.test:\n",
    "        print('The model is set to Testing')\n",
    "        print(\"Check point file: %s\"%args.ckptpath)\n",
    "        #print(\"CamVid testing dir: %s\"%FLAGS.test_dir)\n",
    "    elif args.transfer:\n",
    "        print('The model is set to transfer learn from ckpt')\n",
    "        print(\"Check point file: %s\"%args.ckptpath)\n",
    "        #print(\"CamVid Image dir: %s\"%FLAGS.image_dir)\n",
    "        #print(\"CamVid Val dir: %s\"%FLAGS.val_dir)\n",
    "    else:\n",
    "        print('The model is set to Training')\n",
    "        print(\"Max training Iteration: %d\"%args.max_epoch)\n",
    "        print(\"Initial lr: %f\"%args.lrInit)\n",
    "        print(\"First Drop Steps: %i\"%args.lrDrop1)\n",
    "        print(\"Second Drop Steps: %i\"%args.lrDrop2)\n",
    "        print(\"Data root: %s\"%args.data_root)\n",
    "        print(\"Check point file: %s\"%args.ckptpath)\n",
    "        #print(\"CamVid Val dir: %s\"%FLAGS.val_dir)\n",
    "\n",
    "    print(\"Batch Size: %d\"%args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is set to Testing\n",
      "Check point file: /root/ckpt/segnet_unet_lbw_all_combine_100_epoches\n",
      "Batch Size: 10\n"
     ]
    }
   ],
   "source": [
    "checkArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=Model(args, experiment, loss_weight=(0.5,0.5), mustRestore=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main function\n",
    "def main():    \n",
    "    checkArgs()\n",
    "    if args.train:\n",
    "        transform_train = transforms.Compose([\n",
    "          transforms.Lambda(lambda img: cv2.resize(img, (args.image_w,args.image_h), interpolation=cv2.INTER_CUBIC)),\n",
    "          transforms.Lambda(lambda img: np.expand_dims(img,3) ),\n",
    "          #transforms.Lambda(lambda img: add_artifacts(img,args)),\n",
    "          #transforms.Lambda(lambda img: cv2.transpose(img))\n",
    "        ])\n",
    "        #arprint=ArtPrint(args.data_root, transform=transform_train)\n",
    "        arhh=ArtPrintNoIntsectLBW_biameyd_siameyd(args.data_root, transform=transform_train)\n",
    "        arph=ArtPrintNoIntsectLBW(args.data_root, transform=transform_train)\n",
    "        arpp=ArtPrintNoIntsectLBW_bpr_spr(args.data_root, transform=transform_train)\n",
    "        arhp=ArtPrintNoIntsectLBW_biameyd_sprt(args.data_root, transform=transform_train)\n",
    "        concat=ConcatDataset([arhh,arph,arpp,arhp])\n",
    "        print(len(concat))\n",
    "        idxTrain = int( len(concat)*0.9)\n",
    "        trainset, testset = random_split(concat, [idxTrain, len(concat)-idxTrain])\n",
    "        trainloader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True, drop_last=True,num_workers=4)\n",
    "        testloader = DataLoader(testset, batch_size=args.batch_size, shuffle=False, drop_last=False,num_workers=2)\n",
    "        #return trainset, concat\n",
    "        #weight gen\n",
    "        # modified here:\n",
    "        samples_all=[]\n",
    "        print(trainset.dataset.datasets)\n",
    "        for ds in trainset.dataset.datasets:\n",
    "            samples_all+=ds.samples\n",
    "        #samples_all=trainset.dataset.samples\n",
    "        print(len(samples_all))\n",
    "        print(samples_all[0])\n",
    "        pos_perc=sum(map(lambda x: np.sum(cv2.imread(x[1],cv2.IMREAD_GRAYSCALE)),samples_all))/(args.image_h*args.image_w*len(samples_all))\n",
    "        neg_perc=1-pos_perc\n",
    "        weight=np.array([pos_perc,neg_perc]) # just reverse\n",
    "        print(weight)\n",
    "        model=Model(args, experiment, loss_weight=weight, mustRestore=False)\n",
    "        model.training(loader=trainloader, validateloader=testloader)\n",
    "        \n",
    "    elif args.test:\n",
    "        transform_train = transforms.Compose([\n",
    "          transforms.Lambda(lambda img: cv2.resize(img, (args.image_w,args.image_h), interpolation=cv2.INTER_CUBIC)),\n",
    "          transforms.Lambda(lambda img: np.expand_dims(img,3) ),\n",
    "          #transforms.Lambda(lambda img: add_artifacts(img,args)),\n",
    "          #transforms.Lambda(lambda img: cv2.transpose(img))\n",
    "        ])\n",
    "        irs = IRS(args.data_root,transform=transform_train) #yike todo\n",
    "        testloader = DataLoader(irs, batch_size=args.batch_size, shuffle=False, drop_last=False,num_workers=2)\n",
    "        model=Model(args, experiment, loss_weight=[0.5,0.5], mustRestore=False)\n",
    "        for idx, (images, labels) in enumerate(testloader):\n",
    "            images=images.numpy()\n",
    "            model.imageClean(images)\n",
    "    else:\n",
    "        \n",
    "        pass # for now, leave it pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is set to Testing\n",
      "Check point file: /root/ckpt/segnet_unet_lbw_all_combine_100_epoches\n",
      "Batch Size: 10\n",
      "/root/datasets/irs_handwriting already exists, skipping download\n",
      "GGG\n",
      "[None, 32, 128, 1]\n",
      "0 conv1: (?, ?, ?, 32)\n",
      "0 conv2: (?, ?, ?, 32)\n",
      "1 conv1: (?, ?, ?, 64)\n",
      "1 conv2: (?, ?, ?, 64)\n",
      "2 conv1: (?, ?, ?, 128)\n",
      "2 conv2: (?, ?, ?, 128)\n",
      "1 h_deconv: (?, ?, ?, 64)\n",
      "1 h_deconv_concat: (?, ?, ?, ?)\n",
      "1 h_conv1_post_deconv: (?, ?, ?, 64)\n",
      "1 h_conv2_post_deconv: (?, ?, ?, 64)\n",
      "0 h_deconv: (?, ?, ?, 32)\n",
      "0 h_deconv_concat: (?, ?, ?, ?)\n",
      "0 h_conv1_post_deconv: (?, ?, ?, 32)\n",
      "0 h_conv2_post_deconv: (?, ?, ?, 32)\n",
      "0 outmap: (?, ?, ?, 2)\n",
      "(?, ?, ?, 2)\n",
      "loss: ()\n",
      "INFO:tensorflow:Summary name loss/cross_entropy (raw) is illegal; using loss/cross_entropy__raw_ instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name loss/cross_entropy (raw) is illegal; using loss/cross_entropy__raw_ instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name loss/total_loss (raw) is illegal; using loss/total_loss__raw_ instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name loss/total_loss (raw) is illegal; using loss/total_loss__raw_ instead.\n",
      "COMET ERROR: Failed to extract parameters from Estimator.init()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toto_loss_shape: Tensor(\"loss/total_loss:0\", shape=(), dtype=float32)\n",
      "Python: 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "Tensorflow: 1.12.0-rc0\n",
      "INFO:tensorflow:Restoring parameters from /root/ckpt/segnet_unet_lbw_all_combine_100_epoches/model-80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /root/ckpt/segnet_unet_lbw_all_combine_100_epoches/model-80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init with stored values from /root/ckpt/segnet_unet_lbw_all_combine_100_epoches/model-80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:42: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:42: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "paths=glob(join(args.data_root,'irs_handwriting','**/**/**jpg'))\n",
    "paths_2=glob(join(args.data_root,'small_test_dataset','**jpg'))+glob(join(args.data_root,'small_test_dataset','**png'))\n",
    "#path=paths[15]\n",
    "#img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "#img=cv2.resize(img, (args.image_w,args.image_h), interpolation=cv2.INTER_CUBIC)\n",
    "#img=np.expand_dims(img,3)\n",
    "imgs=[ np.expand_dims(cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE), (args.image_w,args.image_h), interpolation=cv2.INTER_CUBIC),3) for path in paths_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.imageClean(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import, unicode_literals\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time\n",
    "from PIL import Image\n",
    "from math import ceil\n",
    "from collections import OrderedDict\n",
    "import logging\n",
    "'''\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.ops import gen_nn_ops\n",
    "'''\n",
    "# modules\n",
    "\n",
    "from utils import get_image_summary,log_images,_variable_with_weight_decay, _variable_on_cpu, _add_loss_summaries, _activation_summary, print_hist_summery, get_hist, per_class_acc, writeImage\n",
    "\n",
    "#from datasets import ArtPrint\n",
    "from torch.utils.data import DataLoader, ConcatDataset, random_split#, SequentialSampler #yike: add SequentialSampler\n",
    "from os.path import join, basename, dirname\n",
    "#from Inputs import *\n",
    "\n",
    "# model layers\n",
    "def weight_variable(shape, stddev=0.1, name=\"weight\"):\n",
    "    shape=np.array(shape)\n",
    "    #print(shape)\n",
    "    #print(stddev)\n",
    "    initial = tf.truncated_normal(shape, stddev=stddev)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def weight_variable_devonc(shape, stddev=0.1, name=\"weight_devonc\"):\n",
    "    shape=np.array(shape)\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=stddev), name=name)\n",
    "\n",
    "def bias_variable(shape, name=\"bias\"):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def conv2d(x, W, b, keep_prob_):\n",
    "    with tf.name_scope(\"conv2d\"):\n",
    "        conv_2d = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')#'VALID'\n",
    "        conv_2d_b = tf.nn.bias_add(conv_2d, b)\n",
    "        return tf.nn.dropout(conv_2d_b, keep_prob_)\n",
    "\n",
    "def deconv2d(x, W,stride):\n",
    "    with tf.name_scope(\"deconv2d\"):\n",
    "        x_shape = tf.shape(x)\n",
    "        output_shape = tf.stack([x_shape[0], x_shape[1]*2, x_shape[2]*2, x_shape[3]//2])\n",
    "        return tf.nn.conv2d_transpose(x, W, output_shape, strides=[1, stride, stride, 1], padding='SAME', name=\"conv2d_transpose\") #'VALID'\n",
    "\n",
    "def max_pool(x,n):\n",
    "    return tf.nn.max_pool(x, ksize=[1, n, n, 1], strides=[1, n, n, 1], padding='SAME') #'VALID'\n",
    "\n",
    "def crop_and_concat(x1,x2):\n",
    "    with tf.name_scope(\"crop_and_concat\"):\n",
    "        x1_shape = tf.shape(x1)\n",
    "        x2_shape = tf.shape(x2)\n",
    "        # offsets for the top left corner of the crop\n",
    "        offsets = [0, (x1_shape[1] - x2_shape[1]) // 2, (x1_shape[2] - x2_shape[2]) // 2, 0]\n",
    "        size = [-1, x2_shape[1], x2_shape[2], -1]\n",
    "        x1_crop = tf.slice(x1, offsets, size)\n",
    "        return tf.concat([x1_crop, x2], 3)\n",
    "\n",
    "def pixel_wise_softmax(output_map):\n",
    "    with tf.name_scope(\"pixel_wise_softmax\"):\n",
    "        max_axis = tf.reduce_max(output_map, axis=3, keepdims=True)\n",
    "        exponential_map = tf.exp(output_map - max_axis)\n",
    "        normalize = tf.reduce_sum(exponential_map, axis=3, keepdims=True)\n",
    "        return exponential_map / normalize\n",
    "\n",
    "def cross_entropy(y_,output_map):\n",
    "    return -tf.reduce_mean(y_*tf.log(tf.clip_by_value(output_map,1e-10,1.0)), name=\"cross_entropy\")\n",
    "\n",
    "#unet setting\n",
    "def create_conv_net(x, keep_prob, channels, n_class, layers=3, features_root=16, filter_size=3, pool_size=2,\n",
    "                    summaries=True):\n",
    "    \"\"\"\n",
    "    Creates a new convolutional unet for the given parametrization.\n",
    "    :param x: input tensor, shape [?,nx,ny,channels]\n",
    "    :param keep_prob: dropout probability tensor\n",
    "    :param channels: number of channels in the input image\n",
    "    :param n_class: number of output labels\n",
    "    :param layers: number of layers in the net\n",
    "    :param features_root: number of features in the first layer\n",
    "    :param filter_size: size of the convolution filter\n",
    "    :param pool_size: size of the max pooling operation\n",
    "    :param summaries: Flag if summaries should be created\n",
    "    \"\"\"\n",
    "\n",
    "    logging.info(\n",
    "        \"Layers {layers}, features {features}, filter size {filter_size}x{filter_size}, pool size: {pool_size}x{pool_size}\".format(\n",
    "            layers=layers,\n",
    "            features=features_root,\n",
    "            filter_size=filter_size,\n",
    "            pool_size=pool_size))\n",
    "\n",
    "    # Placeholder for the input image\n",
    "    with tf.name_scope(\"preprocessing\"):\n",
    "        nx = tf.shape(x)[1]\n",
    "        ny = tf.shape(x)[2]\n",
    "        #nx=32\n",
    "        #ny=128\n",
    "        #channels=1\n",
    "        x_image = tf.reshape(x, tf.stack([-1, nx, ny, channels]))\n",
    "        in_node = x_image\n",
    "        batch_size = tf.shape(x_image)[0]\n",
    "\n",
    "    weights = []\n",
    "    biases = []\n",
    "    convs = []\n",
    "    pools = OrderedDict()\n",
    "    deconv = OrderedDict()\n",
    "    dw_h_convs = OrderedDict()\n",
    "    up_h_convs = OrderedDict()\n",
    "\n",
    "    in_size = 1000  #?????????????????????\n",
    "    size = in_size\n",
    "    # down layers\n",
    "    for layer in range(0, layers):\n",
    "        with tf.name_scope(\"down_conv_{}\".format(str(layer))):\n",
    "            features = 2 ** layer * features_root\n",
    "            stddev = np.sqrt(2 / (filter_size ** 2 * features))\n",
    "            if layer == 0:\n",
    "                w1 = weight_variable([filter_size, filter_size, channels, features], stddev, name=\"w1\")\n",
    "            else:\n",
    "                w1 = weight_variable([filter_size, filter_size, features // 2, features], stddev, name=\"w1\")\n",
    "\n",
    "            w2 = weight_variable([filter_size, filter_size, features, features], stddev, name=\"w2\")\n",
    "            b1 = bias_variable([features], name=\"b1\")\n",
    "            b2 = bias_variable([features], name=\"b2\")\n",
    "\n",
    "            conv1 = conv2d(in_node, w1, b1, keep_prob)\n",
    "            print(str(layer)+' conv1: '+str(conv1.get_shape()))\n",
    "            tmp_h_conv = tf.nn.relu(conv1)\n",
    "            conv2 = conv2d(tmp_h_conv, w2, b2, keep_prob)\n",
    "            print(str(layer)+' conv2: '+str(conv2.get_shape()))\n",
    "            dw_h_convs[layer] = tf.nn.relu(conv2)\n",
    "\n",
    "            weights.append((w1, w2))\n",
    "            biases.append((b1, b2))\n",
    "            convs.append((conv1, conv2))\n",
    "\n",
    "            size -= 2 * 2 * (filter_size // 2) # valid conv\n",
    "            if layer < layers - 1:\n",
    "                pools[layer] = max_pool(dw_h_convs[layer], pool_size)\n",
    "                in_node = pools[layer]\n",
    "                size /= pool_size\n",
    "\n",
    "    in_node = dw_h_convs[layers - 1]\n",
    "\n",
    "    # up layers\n",
    "    for layer in range(layers - 2, -1, -1):\n",
    "        with tf.name_scope(\"up_conv_{}\".format(str(layer))):\n",
    "            features = 2 ** (layer + 1) * features_root\n",
    "            stddev = np.sqrt(2 / (filter_size ** 2 * features))\n",
    "\n",
    "            wd = weight_variable_devonc([pool_size, pool_size, features // 2, features], stddev, name=\"wd\")\n",
    "            bd = bias_variable([features // 2], name=\"bd\")\n",
    "            h_deconv = tf.nn.relu(deconv2d(in_node, wd, pool_size) + bd)\n",
    "            print(str(layer)+' h_deconv: '+str(h_deconv.get_shape()))\n",
    "            h_deconv_concat = crop_and_concat(dw_h_convs[layer], h_deconv)\n",
    "            print(str(layer)+' h_deconv_concat: '+str(h_deconv_concat.get_shape()))\n",
    "            deconv[layer] = h_deconv_concat\n",
    "\n",
    "            w1 = weight_variable([filter_size, filter_size, features, features // 2], stddev, name=\"w1\")\n",
    "            w2 = weight_variable([filter_size, filter_size, features // 2, features // 2], stddev, name=\"w2\")\n",
    "            b1 = bias_variable([features // 2], name=\"b1\")\n",
    "            b2 = bias_variable([features // 2], name=\"b2\")\n",
    "\n",
    "            conv1 = conv2d(h_deconv_concat, w1, b1, keep_prob)\n",
    "            h_conv = tf.nn.relu(conv1)\n",
    "            print(str(layer)+' h_conv1_post_deconv: '+str(h_conv.get_shape()))\n",
    "            conv2 = conv2d(h_conv, w2, b2, keep_prob)\n",
    "            in_node = tf.nn.relu(conv2)\n",
    "            up_h_convs[layer] = in_node\n",
    "            print(str(layer)+' h_conv2_post_deconv: '+str(in_node.get_shape()))\n",
    "\n",
    "            weights.append((w1, w2))\n",
    "            biases.append((b1, b2))\n",
    "            convs.append((conv1, conv2))\n",
    "\n",
    "            size *= pool_size\n",
    "            size -= 2 * 2 * (filter_size // 2) # valid conv\n",
    "\n",
    "    # Output Map\n",
    "    with tf.name_scope(\"output_map\"):\n",
    "        weight = weight_variable([1, 1, features_root, n_class], stddev)\n",
    "        bias = bias_variable([n_class], name=\"bias\")\n",
    "        conv = conv2d(in_node, weight, bias, tf.constant(1.0))\n",
    "        print(str(layer)+' outmap: '+str(conv.get_shape()))\n",
    "        \n",
    "        #output_map = tf.nn.relu(conv)\n",
    "        output_map=conv # no activation, to be consistant with other models and leverage previous loss/prediction structures yike !!!!\n",
    "        up_h_convs[\"out\"] = output_map\n",
    "\n",
    "    if summaries:\n",
    "        with tf.name_scope(\"summaries\"):\n",
    "            for i, (c1, c2) in enumerate(convs):\n",
    "                tf.summary.image('summary_conv_%02d_01' % i, get_image_summary(c1))\n",
    "                tf.summary.image('summary_conv_%02d_02' % i, get_image_summary(c2))\n",
    "\n",
    "            for k in pools.keys():\n",
    "                tf.summary.image('summary_pool_%02d' % k, get_image_summary(pools[k]))\n",
    "\n",
    "            for k in deconv.keys():\n",
    "                tf.summary.image('summary_deconv_concat_%02d' % k, get_image_summary(deconv[k]))\n",
    "\n",
    "            for k in dw_h_convs.keys():\n",
    "                tf.summary.histogram(\"dw_convolution_%02d\" % k + '/activations', dw_h_convs[k])\n",
    "\n",
    "            for k in up_h_convs.keys():\n",
    "                tf.summary.histogram(\"up_convolution_%s\" % k + '/activations', up_h_convs[k])\n",
    "\n",
    "    variables = []\n",
    "    for w1, w2 in weights:\n",
    "        variables.append(w1)\n",
    "        variables.append(w2)\n",
    "\n",
    "    for b1, b2 in biases:\n",
    "        variables.append(b1)\n",
    "        variables.append(b2)\n",
    "\n",
    "    return output_map, variables, int(in_size - size)\n",
    "\n",
    "### model ###\n",
    "\n",
    "\n",
    "class Model:\n",
    "    # Constants describing the training process. probably move to hyperprameters at main beginning\n",
    "    MOVING_AVERAGE_DECAY = 0.9999     # The decay to use for the moving average.\n",
    "    NUM_EPOCHS_PER_DECAY = 350.0      # Epochs after which learning rate decays.\n",
    "    LEARNING_RATE_DECAY_FACTOR = 0.1  # Learning rate decay factor.\n",
    "    \n",
    "    def __init__(self, args, experiment, loss_weight, mustRestore=False):\n",
    "      \"init model: SegNet model\"\n",
    "      self.args = args\n",
    "      self.experiment=experiment     \n",
    "      self.mustRestore = mustRestore\n",
    "      \n",
    "      ###model hyperparameters###\n",
    "      self.num_classes=args.num_class  \n",
    "      # self.FilePaths = FilePaths\n",
    "      self.batch_size = args.batch_size\n",
    "      self.lrInit = args.lrInit\n",
    "      self.loss_weight=loss_weight\n",
    "      \n",
    "      ###input### -- try to only set up graph once, combine train and test, by yike\n",
    "      tf.reset_default_graph() # yike reset default graph\n",
    "      self.input_images= tf.placeholder( tf.float32, shape=[None, self.args.image_h, self.args.image_w, self.args.image_c]) # try my best to make runtime batch_size flexible\n",
    "      self.input_labels= tf.placeholder(tf.int64, shape=[None, self.args.image_h, self.args.image_w, 1])\n",
    "      self.phase_train= tf.placeholder(tf.bool, name='phase_train')\n",
    "      self.global_step=tf.Variable(0,trainable=False)\n",
    "      self.learning_rate=tf.placeholder(tf.float32, shape=[])\n",
    "    \n",
    "      ###graph### -- combine \n",
    "      self.logit= self.setup_graph(self.input_images, self.phase_train)\n",
    "      self.loss=self.cal_loss(self.logit,self.input_labels) \n",
    "      self.pred=tf.argmax(self.logit,axis=3)\n",
    "      self.train_op=self.train(self.loss,self.learning_rate,self.global_step)\n",
    "\n",
    "      \n",
    "      ###session and saver###\n",
    "      #self.saver=tf.train.Saver(max_to_keep=1)\n",
    "      #self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, gpu_options=tf.GPUOptions(allow_growth=True)))\n",
    "      (self.sess,self.saver) =self.initTF()\n",
    "    \n",
    "    ### 1. loss factory ###\n",
    "    def weighted_loss(self, logits, labels): # num_classes, head=None):\n",
    "      \"\"\" median-frequency re-weighting \"\"\"\n",
    "      with tf.name_scope('loss'):\n",
    "           #print('w_llll')\n",
    "           logits = tf.reshape(logits, (-1, self.num_classes))\n",
    "           #print(logits.get_shape())\n",
    "           epsilon = tf.constant(value=1e-10)\n",
    "\n",
    "           logits = logits + epsilon\n",
    "\n",
    "           # consturct one-hot label array\n",
    "           label_flat = tf.reshape(labels, (-1, 1))\n",
    "           #print(label_flat.get_shape())\n",
    "\n",
    "           # should be [batch ,num_classes]\n",
    "           labels = tf.reshape(tf.one_hot(label_flat, depth=self.num_classes), (-1, self.num_classes))\n",
    "           # print(labels.get_shape())\n",
    "\n",
    "           softmax = tf.nn.softmax(logits)\n",
    "           #print(softmax.get_shape())\n",
    "#        print(epsilon.get_shape())\n",
    "\n",
    "#        print((labels * tf.log(softmax + epsilon)).get_shape())\n",
    "#        print(head.shape)\n",
    "#        print(tf.multiply(labels * tf.log(softmax + epsilon), head))\n",
    "        \n",
    "           cross_entropy = -tf.reduce_sum(tf.multiply(labels * tf.log(softmax + epsilon), self.loss_weight), axis=[1])\n",
    "#        print(cross_entropy.get_shape()) # yike head -> self.loss_weight\n",
    "\n",
    "           cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "#        print(cross_entropy_mean.get_shape())\n",
    "           tf.add_to_collection('losses', cross_entropy_mean)\n",
    "           \n",
    "           loss = tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "           print('loss: '+str(loss.get_shape()))      \n",
    "\n",
    "      return loss\n",
    "    \n",
    "    def cal_loss(self,logits,labels):\n",
    "       labels = tf.cast(labels, tf.int32)\n",
    "       return self.weighted_loss(logits, labels)\n",
    "    #self.weighted_loss(logits, labels, num_classes=NUM_CLASSES, head=loss_weight)\n",
    "    \n",
    "    ###2. train optimizer factory ###    \n",
    "    def train(self,total_loss, lr, global_step):\n",
    "       # all of them are tensor\n",
    "       #total_sample = 274 yike: ok to comment out?\n",
    "       #num_batches_per_epoch = 274/1 yike: ok to comment out?\n",
    "\n",
    "       loss_averages_op = _add_loss_summaries(total_loss)\n",
    "       # Compute gradients.\n",
    "       with tf.control_dependencies([loss_averages_op]):\n",
    "         #print('try...')\n",
    "         opt = tf.train.AdamOptimizer(lr)\n",
    "         print('toto_loss_shape: '+str(total_loss))\n",
    "         opt.compute_gradients(total_loss)\n",
    "         grads = opt.compute_gradients(total_loss)\n",
    "         #print(grads)\n",
    "         apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "         # Add histograms for trainable variables.\n",
    "         for var in tf.trainable_variables():\n",
    "           tf.summary.histogram(var.op.name, var)\n",
    "\n",
    "         # Add histograms for gradients.\n",
    "         for grad, var in grads:\n",
    "           if grad is not None:\n",
    "             tf.summary.histogram(var.op.name + '/gradients', grad)\n",
    "\n",
    "         # Track the moving averages of all trainable variables.\n",
    "         variable_averages = tf.train.ExponentialMovingAverage(Model.MOVING_AVERAGE_DECAY, global_step)\n",
    "         variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "         with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "           train_op = tf.no_op(name='train')\n",
    "\n",
    "       return train_op\n",
    "    \n",
    "    \n",
    "    ###3. graph factory ###\n",
    "    \n",
    "    def setup_graph(self, images, phase_train): # previous inference() labels,inference, batch_size -- in order to get batch_size at running time \n",
    "       #rather than using fixed batch_size in graph set up, revise it in inference:\n",
    "       #batchsize=tf.shape(images)[0] # yike !!!\n",
    "       print('GGG')\n",
    "       input_shape=images.get_shape().as_list()\n",
    "       print(input_shape)\n",
    "\n",
    "#       create_conv_net(x, keep_prob, channels, n_class, layers=3, features_root=16, filter_size=3, pool_size=2,\n",
    "#                    summaries=True) \n",
    "        \n",
    "       logit,_,__=create_conv_net(x=images, keep_prob=0.8, channels=input_shape[3], n_class=self.num_classes, layers=3, features_root=32, filter_size=3) \n",
    "       print(logit.get_shape()) \n",
    "       ''' \n",
    "       \"\"\" Start Classify \"\"\"\n",
    "       \n",
    "       # output predicted class number (6)\n",
    "       with tf.variable_scope('conv_classifier') as scope:\n",
    "         kernel = _variable_with_weight_decay('weights',\n",
    "                                           shape=[1, 1, 64, self.num_classes],\n",
    "                                           initializer=msra_initializer(1, 64),\n",
    "                                           wd=0.0005)\n",
    "         conv = tf.nn.conv2d(conv_decode1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "         print('cv')\n",
    "         print(conv.get_shape())\n",
    "         biases = _variable_on_cpu('biases', [self.num_classes], tf.constant_initializer(0.0))\n",
    "         print(biases.get_shape())\n",
    "         logit= tf.nn.bias_add(conv, biases, name=scope.name)\n",
    "         #conv_classifier = tf.nn.bias_add(conv, biases, name=scope.name)\n",
    "         #print(conv_classifier.get_shape())\n",
    "         #logit = conv_classifier\n",
    "         #print('LLL')\n",
    "         #print(labels)\n",
    "         #print(conv_classifier)\n",
    "    \n",
    "         #loss = cal_loss(conv_classifier, labels)\n",
    "         print(logit.get_shape())\n",
    "         '''\n",
    "       return logit # loss\n",
    "\n",
    "    ###4. initialization###\n",
    "    def initTF(self):\n",
    "       \"initialize TF\"\n",
    "       print('Python: ' + sys.version)\n",
    "       print('Tensorflow: ' + tf.__version__)\n",
    "\n",
    "       sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, gpu_options=tf.GPUOptions(allow_growth=True)))\n",
    "       saver = tf.train.Saver(max_to_keep=1)  # saver saves model to file\n",
    "\n",
    "       # Restore from saved model in current checkpoint directory\n",
    "       latestSnapshot = tf.train.latest_checkpoint(self.args.ckptpath)  # is there a saved model?\n",
    "       if self.mustRestore and not latestSnapshot: # if model must be restored (for inference), there must be a snapshot\n",
    "         raise Exception('No saved model found in: ' + self.args.ckptpath)\n",
    "\n",
    "       if latestSnapshot: # load saved model if available\n",
    "         saver.restore(sess, latestSnapshot)\n",
    "         print('Init with stored values from ' + latestSnapshot)\n",
    "       else:\n",
    "         sess.run(tf.global_variables_initializer())\n",
    "         print('Ran global_variables_initializer')\n",
    "\n",
    "         # initialize params from other model (transfer learning)\n",
    "       if self.args.transfer:\n",
    "         utils.maybe_download(source_url=self.args.urlTransferFrom,\n",
    "                         filename=join(self.args.ckptpath, 'transferFrom'),\n",
    "                         target_directory=None,\n",
    "                         filetype='folder',\n",
    "                         force=True)\n",
    "         saverTransfer = tf.train.Saver(tf.trainable_variables()[:-1])  # load all variables except from logit (classification) layer\n",
    "         saverTransfer.restore(sess, glob(join(self.args.ckptpath, 'transferFrom', 'model*'))[0].split('.')[0])\n",
    "         print('Loaded variable values (except logit layer) from ' + self.args.urlTransferFrom)\n",
    "\n",
    "       return (sess, saver) \n",
    "    \n",
    "    ###5. training ###\n",
    "    def trainBatch(self, images, labels):\n",
    "       \"feed a batch into the NN to train it\"\n",
    "    \n",
    "       #sparse = self.toSparse(labels)\n",
    "       #lrnrate = self.lrInit if self.batchesTrained < self.args.lrDrop1 else (\n",
    "       #self.lrInit*1e-1 if self.batchesTrained < self.args.lrDrop2 else self.lrInit*1e-2)  # decay learning rate\n",
    "       train_step=self.global_step.eval(session=self.sess)\n",
    "       \"\"\" fix lr \"\"\" ## To Ronny, change the schedule?\n",
    "       #lr = self.lrInit\n",
    "       lr = self.lrInit if train_step < self.args.lrDrop1 else (\n",
    "            self.lrInit*1e-1 if train_step < self.args.lrDrop2 else self.lrInit*1e-2) #yike\n",
    "       (_, lossVal) = self.sess.run([self.train_op, self.loss],\n",
    "                                  {self.input_images: images,\n",
    "                                   self.input_labels: labels,\n",
    "                                   self.learning_rate: lr, \n",
    "                                   self.phase_train: True})\n",
    "       #self.batchesTrained += 1\n",
    "       return lossVal\n",
    "    \n",
    "    def training(self, loader, validateloader=None,testloader=None):\n",
    "       \"train NN\"\n",
    "       epoch = 0  # number of training epochs since start\n",
    "       best_accuracy=0.0\n",
    "       step = 0\n",
    "       while True:\n",
    "         epoch += 1; print('Epoch:', epoch, ' Training...')\n",
    "         # train\n",
    "         counter = 0\n",
    "         #step = 0 \n",
    "         for idx, (images, labels) in enumerate(loader):\n",
    "            images=images.numpy()\n",
    "            labels=labels.numpy()\n",
    "            loss_value=self.trainBatch(images,labels)\n",
    "            assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "            step+=1\n",
    "            \n",
    "            if idx % 100 ==0:\n",
    "              print('TRAIN: Batch:', idx/len(loader), 'Loss:', loss_value)\n",
    "              self.experiment.log_metric('train/loss', loss_value, step)\n",
    "              logits=self.sess.run(self.logit, feed_dict={self.input_images: images, # check in, comment out in formal run\n",
    "                                   #self.input_labels: labels,\n",
    "                                   #self.learning_rate: lr, \n",
    "                                   self.phase_train: False})\n",
    "              train_acc,train_acc_classes=per_class_acc(logits,labels)  # check in, comment out in formal run\n",
    "\n",
    "         # train log:\n",
    "         self.experiment.log_metric('train/acc',train_acc,step)\n",
    "         self.experiment.log_metric('train/cap_0',train_acc_classes[0],step)\n",
    "         self.experiment.log_metric('train/cap_1',train_acc_classes[1],step)\n",
    "                \n",
    "         #validate:\n",
    "         if validateloader !=None: \n",
    "           avg_batch_loss,acc_total,cap_0,cap_1=self.validate(validateloader,epoch)\n",
    "         else:\n",
    "           avg_batch_loss,acc_total,cap_0,cap_1=self.validate(loader,epoch)\n",
    "         self.experiment.log_metric('valid/acc',acc_total,step)\n",
    "         self.experiment.log_metric('valid/cap_0',cap_0,step)\n",
    "         self.experiment.log_metric('valid/cap_1',cap_1,step)\n",
    "         self.experiment.log_metric('valid/loss',avg_batch_loss,step)   \n",
    "         \n",
    "\n",
    "         #test:\n",
    "         if testloader !=None:\n",
    "           acc_total,cap_0,cap_1=self.validate(testloader,epoch,is_testing=True)\n",
    "           self.experiment.log_metric('test/acc',acc_total,step)\n",
    "           self.experiment.log_metric('test/cap_0',cap_0,step)\n",
    "           self.experiment.log_metric('test/cap_1',cap_1,step)\n",
    "           \n",
    "         # log best metrics\n",
    "         if acc_total > best_accuracy: # if best validation accuracy so far, save model parameters\n",
    "           print('Character error rate improved, save model')\n",
    "           best_accuracy = acc_total\n",
    "           noImprovementSince = 0\n",
    "           self.save(epoch)\n",
    "           open(join(self.args.ckptpath, 'accuracy.txt'), 'w').write('Validation accuracy, class 0, class 1 capture rates of saved model: %f%%, %f%% and %f%% ' % (acc_total * 100.0, cap_0 * 100.0, cap_1 * 100.0))\n",
    "           self.experiment.log_metric('best/acc',acc_total,step)\n",
    "           self.experiment.log_metric('best/cap_0',cap_0,step)\n",
    "           self.experiment.log_metric('best/cap_1',cap_1,step)         \n",
    "         else:\n",
    "           print('Character error rate not improved')\n",
    "           noImprovementSince += 1\n",
    "\n",
    "         # stop training\n",
    "         if epoch>=self.args.max_epoch: print('Done with training at epoch', epoch, 'sigoptObservation='+str(best_accuracy)); break            \n",
    "            \n",
    "            \n",
    "    ###6. testing / validate ###\n",
    "    def validate(self, loader, epoch, is_testing=False):\n",
    "       \"validate NN\"\n",
    "       if not is_testing: print('Validating NN')\n",
    "       else: print('Testing NN')\n",
    "       total_val_loss = 0.0\n",
    "       #num_batches=len(loader)\n",
    "       hist= np.zeros((self.num_classes, self.num_classes))\n",
    "        \n",
    "       image_upload_count=0 \n",
    "       for idx, (images, labels) in enumerate(loader):\n",
    "         images=images.numpy()\n",
    "         labels=labels.numpy()\n",
    "         val_loss,val_logit=self.sess.run([self.loss,self.logit],feed_dict=\n",
    "                                {self.input_images: images, # check in, comment out in formal run\n",
    "                                self.input_labels: labels,\n",
    "                                self.phase_train: False}) #self.loss,val_loss,\n",
    "          \n",
    "         total_val_loss+=val_loss\n",
    "         hist+=get_hist(val_logit,labels)\n",
    "       #val_loss=total_val_loss / len(validateloader)*batch_size\n",
    "\n",
    "         if epoch==self.args.max_epoch and image_upload_count<1000: # decide how many images to upload\n",
    "            pred=val_logit.argmax(3)\n",
    "            images=np.squeeze(images,axis=3)\n",
    "            image_upload_count=log_images(images,pred,image_upload_count,self.experiment,self.args.ckptpath)\n",
    "            \n",
    "       avg_batch_loss=total_val_loss/idx     \n",
    "       cls_sample_nums=hist.sum(1).astype(float)\n",
    "       capture_array=np.diag(hist)\n",
    "       acc_total = capture_array.sum() / hist.sum()\n",
    "       capture_rate_ls=[]\n",
    "       for cls in range(self.num_classes):\n",
    "         if cls_sample_nums[cls]==0:\n",
    "            capture_rate=0.0\n",
    "         else:\n",
    "            capture_rate=capture_array[cls]/cls_sample_nums[cls]\n",
    "         capture_rate_ls.append(capture_rate)\n",
    "       #iu = np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))\n",
    "       #mean_iu=np.nanmean(iu)\n",
    "       print('VALID: Total accuracy: %f%%. Class 0 capture: %f%%. Class 1 capture: %f%%' % (acc_total * 100.0, capture_rate_ls[0] * 100.0, capture_rate_ls[1]*100.0)) \n",
    "       return avg_batch_loss,acc_total,capture_rate_ls[0],capture_rate_ls[1]\n",
    "    \n",
    "    ###7. infer ###\n",
    "    def inferBatch(self, imgs): # modify to compatible to torch. previous def inferBatch(self, batch)\n",
    "       \"feed a batch into the NN to recngnize the texts\"\n",
    "  \n",
    "       bt_size=len(imgs) # yike !!!!!!!!\n",
    "\n",
    "       pred = self.sess.run(self.pred,feed_dict=\n",
    "                                {self.input_images: imgs, # check in, comment out in formal run\n",
    "                                #self.input_labels: labels,\n",
    "                                self.phase_train: False}) #yike self.batchsize!!!!!!!!!\n",
    "       return pred\n",
    "    def imageClean(self,imgs):\n",
    "       pred=self.inferBatch(imgs)\n",
    "       bt_size=len(imgs)\n",
    "       images=np.squeeze(imgs,axis=3)\n",
    "       image_upload_count=log_images(imgs,pred,0,self.experiment,self.args.ckptpath) #image_upload_count\n",
    "       \n",
    "    \n",
    "    ###8. save  ###\n",
    "    def save(self, epoch):\n",
    "       \"save model to file\"\n",
    "       self.saver.save(self.sess, join(self.args.ckptpath, 'model'), global_step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#main function\n",
    "def main():    \n",
    "    checkArgs()\n",
    "    if args.train:\n",
    "        transform_train = transforms.Compose([\n",
    "          transforms.Lambda(lambda img: cv2.resize(img, (args.image_w,args.image_h), interpolation=cv2.INTER_CUBIC)),\n",
    "          transforms.Lambda(lambda img: np.expand_dims(img,3) ),\n",
    "          #transforms.Lambda(lambda img: add_artifacts(img,args)),\n",
    "          #transforms.Lambda(lambda img: cv2.transpose(img))\n",
    "        ])\n",
    "        #arprint=ArtPrint(args.data_root, transform=transform_train)\n",
    "        arhh=ArtPrintNoIntsectLBW_biameyd_siameyd(args.data_root, transform=transform_train)\n",
    "        arph=ArtPrintNoIntsectLBW(args.data_root, transform=transform_train)\n",
    "        arpp=ArtPrintNoIntsectLBW_bpr_spr(args.data_root, transform=transform_train)\n",
    "        arhp=ArtPrintNoIntsectLBW_biameyd_sprt(args.data_root, transform=transform_train)\n",
    "        concat=ConcatDataset([arhh,arph,arpp,arhp])\n",
    "        print(len(concat))\n",
    "        idxTrain = int( len(concat)*0.9)\n",
    "        trainset, testset = random_split(concat, [idxTrain, len(concat)-idxTrain])\n",
    "        trainloader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True, drop_last=True,num_workers=4)\n",
    "        testloader = DataLoader(testset, batch_size=args.batch_size, shuffle=False, drop_last=False,num_workers=2)\n",
    "        #return trainset, concat\n",
    "        #weight gen\n",
    "        # modified here:\n",
    "        samples_all=[]\n",
    "        print(trainset.dataset.datasets)\n",
    "        for ds in trainset.dataset.datasets:\n",
    "            samples_all+=ds.samples\n",
    "        #samples_all=trainset.dataset.samples\n",
    "        print(len(samples_all))\n",
    "        print(samples_all[0])\n",
    "        pos_perc=sum(map(lambda x: np.sum(cv2.imread(x[1],cv2.IMREAD_GRAYSCALE)),samples_all))/(args.image_h*args.image_w*len(samples_all))\n",
    "        neg_perc=1-pos_perc\n",
    "        weight=np.array([pos_perc,neg_perc]) # just reverse\n",
    "        print(weight)\n",
    "        model=Model(args, experiment, loss_weight=weight, mustRestore=False)\n",
    "        model.training(loader=trainloader, validateloader=testloader)\n",
    "        \n",
    "    elif:\n",
    "        transform_train = transforms.Compose([\n",
    "          transforms.Lambda(lambda img: cv2.resize(img, (args.image_w,args.image_h), interpolation=cv2.INTER_CUBIC)),\n",
    "          transforms.Lambda(lambda img: np.expand_dims(img,3) ),\n",
    "          #transforms.Lambda(lambda img: add_artifacts(img,args)),\n",
    "          #transforms.Lambda(lambda img: cv2.transpose(img))\n",
    "        ])\n",
    "        irs = IRS(args.dataroot,transform=transform_train) #yike todo\n",
    "        testloader = DataLoader(irs, batch_size=args.batch_size, shuffle=False, drop_last=False,num_workers=2)\n",
    "        model=Model(args, experiment, loss_weight=[0.5,0.5], mustRestore=False)\n",
    "        for idx, (images, labels) in enumerate(loader):\n",
    "            images=images.numpy()\n",
    "            model.imageClean(images)\n",
    "    else:\n",
    "        \n",
    "        pass # for now, leave it pass \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
