{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: old comet version (1.0.44) detected. current: 2.0.5 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
      "COMET WARNING: Failing to collect the installed os packages\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/yikeqicn/segnet-recognition-joint/c3d99b21173543a59d311b6bcd790208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "from comet_ml import Experiment\n",
    "experiment = Experiment(api_key=\"YkPEmantOag1R1VOJmXz11hmt\", parse_args=False, project_name='SegNet_Recognition_Joint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datasets import IRSPRT#RecgArtPrintNoIntsectHVBW\n",
    "import pytesseract as pyt\n",
    "from os.path import join, basename, dirname\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import editdistance\n",
    "\n",
    "from torch.utils.data import DataLoader, ConcatDataset, random_split#, SequentialSampler #yike: add SequentialSampler\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "#from datasets import IRS #ArtPrintNoIntsectLBW,ArtPrintNoIntsectLBW_biameyd_siameyd,ArtPrintNoIntsectLBW_bpr_spr,ArtPrintNoIntsectLBW_biameyd_sprt\n",
    "############from Model_Unet_github import *\n",
    "from utils_seg import *\n",
    "import utils_recg\n",
    "\n",
    "\n",
    "from Model_Binary_Joint import *\n",
    "############from recognition.Model import RecgModel, DecoderType\n",
    "#from recognition.utils import log_image\n",
    "\n",
    "home = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hoffline Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lines(cv_img):\n",
    "    cv_img_copy=cv_img.copy()\n",
    "    #gray = cv2.cvtColor(cv_img_copy,cv2.COLOR_BGR2GRAY)\n",
    "    gray=cv_img_copy\n",
    "    gray = cv2.GaussianBlur(gray,(3,3),0)\n",
    "    height,width=gray.shape\n",
    "    edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "    minLineLength = 60\n",
    "    maxLineGap = 15\n",
    "    lines = cv2.HoughLinesP(edges,1,np.pi/180,50,minLineLength,maxLineGap)\n",
    "    if lines is None or len(lines)==0:\n",
    "        return cv_img_copy\n",
    "    for line in lines:\n",
    "        x1,y1,x2,y2=line[0]\n",
    "        if np.abs(x2-x1)>minLineLength:\n",
    "            cv2.line(cv_img_copy,(0,y1),(width,y2),(255,255,255),3) #BGR\n",
    "        else:\n",
    "            cv2.line(cv_img_copy,(x1,0),(x2,height),(255,255,255),3)\n",
    "    return cv_img_copy        \n",
    "\n",
    "def highlight_lines(cv_img):\n",
    "    cv_img_copy=cv_img.copy()\n",
    "    gray = cv2.cvtColor(cv_img_copy,cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray,(3,3),0)\n",
    "    height,width=gray.shape\n",
    "    edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "    minLineLength = 30\n",
    "    maxLineGap = 15\n",
    "    lines = cv2.HoughLinesP(edges,1,np.pi/180,50,minLineLength,maxLineGap)\n",
    "    for line in lines:\n",
    "        x1,y1,x2,y2=line[0]\n",
    "        if np.abs(x2-x1)>minLineLength:\n",
    "            cv2.line(cv_img_copy,(0,y1),(width,y2),(0,255,0),6) #BGR\n",
    "        else:\n",
    "            cv2.line(cv_img_copy,(x1,0),(x2,height),(0,255,0),6)\n",
    "    return cv_img_copy      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-urlTranferFrom'], dest='urlTranferFrom', nargs=None, const=None, default='', type=<class 'str'>, choices=None, help=' archived model url ', metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#General Settings\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# system basics\n",
    "#parser.add_argument(\"-name\", default='segnet_unet_hvbw_all_combine_100_epoches', type=str, help=\"name of the log\") #debug model_intersect # segnet_no_intersect_1conv_64_channels_30epoch_unet_github\n",
    "parser.add_argument(\"-name_seg\", default='new_segnet_joint', type=str, help=\"name of the log\") #debug model_intersect # segnet_no_intersect_1conv_64_channels_30epoch_unet_github\n",
    "#segnet_binary_100epoch_unet_github\n",
    "parser.add_argument(\"-gpu\", default='-1', type=str, help=\"gpu numbers\")\n",
    "\n",
    "parser.add_argument(\"-train\", default=False, help=\"train the NN\", action=\"store_true\")\n",
    "parser.add_argument(\"-validate\", help=\"validate the NN\", action=\"store_true\")\n",
    "\n",
    "parser.add_argument(\"-transfer\",default=False, help=\"test the NN\", action=\"store_true\")\n",
    "\n",
    "parser.add_argument(\"-test\",default=True, help=\"test the NN\", action=\"store_true\")\n",
    "\n",
    "# image and logistic parameters \n",
    "parser.add_argument(\"-image_h\", default=32, type=int, help='image height') #('image_h', \"360\", \"\"\" image height \"\"\") 32\n",
    "parser.add_argument(\"-image_w\", default=128, type=int, help='image width')#('image_w', \"480\", \"\"\" image width \"\"\")128\n",
    "#parser.add_argument(\"-image_h\", default=360, type=int, help='image height') \n",
    "#parser.add_argument(\"-image_w\", default=480, type=int, help='image width')\n",
    "\n",
    "parser.add_argument(\"-image_c\", default=1, type=int, help='image channel')#('image_c', \"3\", \"\"\" image channel (RGB) \"\"\")\n",
    "parser.add_argument(\"-num_class\", default=2, type=int, help='total class number')\n",
    "\n",
    "# training hyperparam\n",
    "parser.add_argument(\"-batch_size_seg\", default=10, type=int, help='batch_size')\n",
    "parser.add_argument(\"-lrInit\", default=1e-3, type=int, help='initial lr')\n",
    "parser.add_argument(\"-lrDrop1\", default=10, type=int, help='step to drop lr by 10 first time') # not sure\n",
    "parser.add_argument(\"-lrDrop2\", default=1000, type=int, help='step to drop lr by 10 sexond time') # not sure\n",
    "parser.add_argument('-max_epoch',default=100, type=int,help='max epoch numbers')\n",
    "\n",
    "\n",
    "\n",
    "# file paths\n",
    "parser.add_argument('-ckpt_root', default=\"/root/ckpt\", type=str,help= \"dir to store ckpt\") # log_dir !!!!!\n",
    "parser.add_argument('-data_root', default=\"/root/datasets\", type=str, help=\" root to any data folder \")\n",
    "parser.add_argument('-urlTranferFrom', default=\"\", type=str, help=\" archived model url \")\n",
    "\n",
    "\n",
    "#args = parser.parse_args()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognition Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognition Model\n",
    "# basic operations\n",
    "parser.add_argument(\"-name_recg\", default=\"recg_new_five_datasets\", type=str, help=\"name of the log\") #'dense_128_32_noartifact_beamsearch_5_datasets'\n",
    "#parser.add_argument(\"-gpu\", default='-1', type=str, help=\"gpu numbers\")\n",
    "#parser.add_argument(\"-train\", help=\"train the NN\", action=\"store_true\")\n",
    "#parser.add_argument(\"-validate\", help=\"validate the NN\", action=\"store_true\")\n",
    "#parser.add_argument(\"-transfer\", action=\"store_true\")\n",
    "#actually not effective:\n",
    "parser.add_argument(\"-batchesTrained\", default=0, type=int, help='number of batches already trained (for lr schedule)') \n",
    "# beam search\n",
    "parser.add_argument(\"-beamsearch\", help=\"use beam search instead of best path decoding\",default=True, action=\"store_true\")\n",
    "parser.add_argument(\"-wordbeamsearch\", help=\"use word beam search instead of best path decoding\", action=\"store_true\")\n",
    "# training hyperparam\n",
    "parser.add_argument(\"-batchsize_recg\", default=10, type=int, help='batch size') # actually not effective in infrerence\n",
    "#parser.add_argument(\"-lrInit\", default=1e-2, type=float, help='initial learning rate') # actually not effective\n",
    "parser.add_argument(\"-optimizer\", default='rmsprop', help=\"adam, rmsprop, momentum\") # actually not effective\n",
    "parser.add_argument(\"-wdec\", default=1e-4, type=float, help='weight decay') # acctually not effective\n",
    "#parser.add_argument(\"-lrDrop1\", default=10, type=int, help='step to drop lr by 10 first time')\n",
    "#parser.add_argument(\"-lrDrop2\", default=1000, type=int, help='step to drop lr by 10 sexond time')\n",
    "parser.add_argument(\"-epochEnd\", default=40, type=int, help='end after this many epochs')\n",
    "# trainset hyperparam\n",
    "#parser.add_argument(\"-noncustom\", help=\"noncustom (original) augmentation technique\", action=\"store_true\")\n",
    "#parser.add_argument(\"-noartifact\", help=\"dont insert artifcats\", action=\"store_true\")\n",
    "#parser.add_argument(\"-iam\", help='use iam dataset', action='store_true')\n",
    "# densenet hyperparam\n",
    "parser.add_argument(\"-nondensenet\", help=\"use noncustom (original) vanilla cnn\", action=\"store_true\")\n",
    "parser.add_argument(\"-growth_rate\", default=12, type=int, help='growth rate (k)')\n",
    "parser.add_argument(\"-layers_per_block\", default=18, type=int, help='number of layers per block')\n",
    "parser.add_argument(\"-total_blocks\", default=5, type=int, help='nuber of densenet blocks')\n",
    "parser.add_argument(\"-keep_prob\", default=1, type=float, help='keep probability in dropout')\n",
    "parser.add_argument(\"-reduction\", default=0.4, type=float, help='reduction factor in 1x1 conv in transition layers')\n",
    "parser.add_argument(\"-bc_mode\", default=True, type=bool, help=\"bottleneck and compresssion mode\")\n",
    "# rnn,  hyperparams\n",
    "parser.add_argument(\"-rnndim\", default=256, type=int, help='rnn dimenstionality') #256\n",
    "parser.add_argument(\"-rnnsteps\", default=32, type=int, help='number of desired time steps (image slices) to feed rnn')\n",
    "# img size\n",
    "parser.add_argument(\"-imgsize\", default=[128,32], type=int, nargs='+') #qyk default 128,32 // use segnet definition\n",
    "# testset crop\n",
    "#parser.add_argument(\"-crop_r1\", default=3, type=int)\n",
    "#parser.add_argument(\"-crop_r2\", default=28, type=int)\n",
    "#parser.add_argument(\"-crop_c1\", default=10, type=int)\n",
    "#parser.add_argument(\"-crop_c2\", default=115, type=int)\n",
    "# filepaths\n",
    "parser.add_argument(\"-dataroot\", default='/root/datasets', type=str)\n",
    "#######parser.add_argument(\"-ckptroot\", default='/root/ckpt', type=str)##############\n",
    "#parser.add_argument(\"-urlTransferFrom\", default=None, type=str)\n",
    "\n",
    "args = parser.parse_known_args()[0]\n",
    "\n",
    "### SegNet\n",
    "home = os.environ['HOME']\n",
    "#name = args.name\n",
    "#ckptroot = join(home, 'ckpt')\n",
    "#args.ckptpath = join(ckptroot, name)\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "\n",
    "####args = parser.parse_known_args()[0]\n",
    "\n",
    "name_seg = args.name_seg\n",
    "name_recg=args.name_recg\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "\n",
    "ckptroot = args.ckpt_root\n",
    "args.ckptpath_seg = join(ckptroot, name_seg)\n",
    "args.ckptpath_recg = join(ckptroot, name_recg)\n",
    "if args.name_seg=='debug_seg_': shutil.rmtree(args.ckptpath_seg, ignore_errors=True)\n",
    "if args.name_recg=='debug_recg_': shutil.rmtree(args.ckptpath_recg, ignore_errors=True)\n",
    "\n",
    "os.makedirs(args.ckptpath_seg, exist_ok=True)\n",
    "os.makedirs(args.ckptpath_recg, exist_ok=True)\n",
    "\n",
    "#recg_name=args.recg_name\n",
    "#args.regckptpath=join(ckptroot,recg_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.set_name('JointRecognitionTest_SameD_houghline_psm7_dilate')\n",
    "experiment.log_parameters(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets_seg import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/datasets/artifact_images_no_intersect already exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: cv2.resize(img, (args.image_w,args.image_h), interpolation=cv2.INTER_CUBIC)),\n",
    "    transforms.Lambda(lambda img: np.expand_dims(img,3) ),\n",
    "    #transforms.Lambda(lambda img: add_artifacts(img,args)),\n",
    "    #transforms.Lambda(lambda img: cv2.transpose(img))\n",
    "    ])\n",
    "testset=ArtPrintNoIntsectBinary_20000(transform=transform_train)\n",
    "testloader = DataLoader(testset, batch_size=args.batch_size_seg, shuffle=False, drop_last=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET ERROR: File could not be uploaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.03\n",
      "0.035\n",
      "0.04\n",
      "0.045\n",
      "0.05\n",
      "0.055\n",
      "0.06\n",
      "0.065\n",
      "0.07\n",
      "0.075\n",
      "0.08\n",
      "0.085\n",
      "0.09\n",
      "0.095\n",
      "VALID: Character error rate: 41.293500%. Word accuracy: 4.955000%.\n",
      "VALID: Cleaned Character error rate: 42.337000%. Cleaned Word accuracy: 6.330000%.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f50f1d59cc0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "  upload=True\n",
    "  numCharErr, numCharTotal, numWordOK, numWordTotal = 0, 0, 0, 0\n",
    "  numCharErrClean, numWordOKClean = 0, 0\n",
    "  kernel = np.ones((2,2), np.uint8)\n",
    "  #plt.figure(figsize=(6,2))\n",
    "  counter = 0\n",
    "  lenidx=len(testset)\n",
    "  for idx, (images,_,labels) in enumerate(testloader):\n",
    "    \n",
    "    if np.mod(idx,100)==0:\n",
    "      print(str(idx/lenidx))\n",
    "    images=images.numpy()\n",
    "    \n",
    "    #cleaneds,clean_recgs=model_joint.inferCleanBatchJoint(images);\n",
    "    #cleaneds=model_joint.imageCleanSeg(images);\n",
    "    images=np.squeeze(images,3)\n",
    "    #org_recgs=model_recg.inferBatchRecg(np.transpose(images,axes=(2,3)));\n",
    "    \n",
    "    #cleaned_list=model.imageClean2(images)\n",
    "\n",
    "    for img,label in zip(images,labels):\n",
    "        #img=np.squeeze(img,3)\n",
    "        #img_cl= np.squeeze(img_cl).astype(np.dtype('uint8'))\n",
    "        img_pil=Image.fromarray(img)\n",
    "        img_cl=clean_lines(img)\n",
    "        img_cl=cv2.dilate(img_cl, kernel, iterations=1)\n",
    "        img_cl=cv2.erode(img_cl, kernel, iterations=1)\n",
    "        img_cl_pil=Image.fromarray(img_cl)\n",
    "        \n",
    "        rec=pyt.image_to_string(img_pil,config='-psm 7')\n",
    "        rec_cl=pyt.image_to_string(img_cl_pil,config='-psm 7')\n",
    "        \n",
    "        \n",
    "        numWordOK += 1 if label == rec else 0 #batch.gtTexts[i]\n",
    "        numWordTotal += 1\n",
    "        dist0 = editdistance.eval(rec, label)# batch.gtTexts[i])\n",
    "        numCharErr += dist0\n",
    "        numCharTotal += len(labels)\n",
    "        \n",
    "        numWordOKClean += 1 if label == rec_cl else 0 #batch.gtTexts[i]\n",
    "        #numWordTotal += 1\n",
    "        dist1 = editdistance.eval(rec_cl, label)# batch.gtTexts[i])\n",
    "        numCharErrClean+= dist1\n",
    "        #numCharTotal += len(labels)\n",
    "        \n",
    "        if upload and counter<2000: # log images\n",
    "            im_save=np.concatenate((img,img_cl),axis=1)\n",
    "            text = ' '.join(['[OK]' if dist1 == 0 else '[ERR:%d]' % dist1,'<=','[OK]' if dist0 == 0 else '[ERR:%d]' % dist0,': ' ,'\"' + label + '\"', '->', '\"' + rec + '\"', '->', '\"' + rec_cl + '\"'])\n",
    "            log_image2(experiment, im_save, text, 'test_remove_artifacts', args.ckptpath_seg, counter)\n",
    "        \n",
    "        \n",
    "        counter+=1\n",
    "        \n",
    "\n",
    "  charErrorRate = numCharErr / numCharTotal\n",
    "  wordAccuracy = numWordOK / numWordTotal\n",
    "  charErrorRateClean = numCharErrClean / numCharTotal\n",
    "  wordAccuracyClean = numWordOKClean / numWordTotal\n",
    "  print('VALID: Character error rate: %f%%. Word accuracy: %f%%.' % (charErrorRate * 100.0, wordAccuracy * 100.0))\n",
    "  print('VALID: Cleaned Character error rate: %f%%. Cleaned Word accuracy: %f%%.' % (charErrorRateClean * 100.0, wordAccuracyClean * 100.0))\n",
    "  experiment.log_metric('valid/raw/cer', charErrorRate)#, step)\n",
    "  experiment.log_metric('valid/raw/wer', 1-wordAccuracy)#, step)\n",
    "  experiment.log_metric('valid/clean/cer', charErrorRateClean)#, step)\n",
    "  experiment.log_metric('valid/clean/wer', 1-wordAccuracyClean)#, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: Character error rate: 34.987826%. Word accuracy: 6.112309%.\n",
      "VALID: Cleaned Character error rate: 6.821115%. Cleaned Word accuracy: 66.673094%.\n"
     ]
    }
   ],
   "source": [
    "  charErrorRate = numCharErr / numCharTotal\n",
    "  wordAccuracy = numWordOK / numWordTotal\n",
    "  charErrorRateClean = numCharErrClean / numCharTotal\n",
    "  wordAccuracyClean = numWordOKClean / numWordTotal\n",
    "  print('VALID: Character error rate: %f%%. Word accuracy: %f%%.' % (charErrorRate * 100.0, wordAccuracy * 100.0))\n",
    "  print('VALID: Cleaned Character error rate: %f%%. Cleaned Word accuracy: %f%%.' % (charErrorRateClean * 100.0, wordAccuracyClean * 100.0))\n",
    "  experiment.log_metric('valid/raw/cer', charErrorRate)#, step)\n",
    "  experiment.log_metric('valid/raw/wer', 1-wordAccuracy)#, step)\n",
    "  experiment.log_metric('valid/clean/cer', charErrorRateClean)#, step)\n",
    "  experiment.log_metric('valid/clean/wer', 1-wordAccuracyClean)#, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GGG\n",
      "[None, 32, 128, 1]\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/Engagements/Unet_Recognition_Joint/src/Model_Binary_Joint.py:52: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/Engagements/Unet_Recognition_Joint/src/Model_Binary_Joint.py:52: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py:3042: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py:3042: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1: (?, ?, ?, 32)\n",
      "0 conv2: (?, ?, ?, 32)\n",
      "1 conv1: (?, ?, ?, 64)\n",
      "1 conv2: (?, ?, ?, 64)\n",
      "2 conv1: (?, ?, ?, 128)\n",
      "2 conv2: (?, ?, ?, 128)\n",
      "1 h_deconv: (?, ?, ?, 64)\n",
      "1 h_deconv_concat: (?, ?, ?, ?)\n",
      "1 h_conv1_post_deconv: (?, ?, ?, 64)\n",
      "1 h_conv2_post_deconv: (?, ?, ?, 64)\n",
      "0 h_deconv: (?, ?, ?, 32)\n",
      "0 h_deconv_concat: (?, ?, ?, ?)\n",
      "0 h_conv1_post_deconv: (?, ?, ?, 32)\n",
      "0 h_conv2_post_deconv: (?, ?, ?, 32)\n",
      "0 outmap: (?, ?, ?, 2)\n",
      "(?, ?, ?, 2)\n",
      "loss_seg: ()\n",
      "WARNING:tensorflow:From /root/Engagements/Unet_Recognition_Joint/src/Model_Binary_Joint.py:313: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/Engagements/Unet_Recognition_Joint/src/Model_Binary_Joint.py:313: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean output from seg: (?, 32, 128)\n",
      "recg input: (?, 128, 32)\n",
      "shape of cnn input: [None, 128, 32]\n",
      "Build Densenet4htr model with 5 blocks, 9 bottleneck layers and 9 composite layers each.\n",
      "Depth: 96\n",
      "Reduction at transition layers: 0.4\n",
      "densenet feature extractor graph built in (sec): 7.639151096343994\n",
      "Total training params: 1.0M\n",
      "shape of cnn output: [None, 32, 1, 178]\n",
      "WARNING:tensorflow:From /root/Engagements/Unet_Recognition_Joint/src/Model_Binary_Joint.py:544: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/Engagements/Unet_Recognition_Joint/src/Model_Binary_Joint.py:544: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/Engagements/Unet_Recognition_Joint/src/Model_Binary_Joint.py:547: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/Engagements/Unet_Recognition_Joint/src/Model_Binary_Joint.py:547: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/Engagements/Unet_Recognition_Joint/src/Model_Binary_Joint.py:552: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/Engagements/Unet_Recognition_Joint/src/Model_Binary_Joint.py:552: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/util/decorator_utils.py:145: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/util/decorator_utils.py:145: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name graph_segmentation/loss/cross_entropy (raw) is illegal; using graph_segmentation/loss/cross_entropy__raw_ instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name graph_segmentation/loss/cross_entropy (raw) is illegal; using graph_segmentation/loss/cross_entropy__raw_ instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name add (raw) is illegal; using add__raw_ instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name add (raw) is illegal; using add__raw_ instead.\n",
      "COMET ERROR: Failed to extract parameters from Estimator.init()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toto_loss_shape: Tensor(\"add:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3197: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3197: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "COMET ERROR: Failed to extract parameters from Estimator.init()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "Tensorflow: 1.12.0-rc0\n",
      "Ran global_variables_initializer first\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1557: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1557: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /root/ckpt/new_segnet_joint/model-99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /root/ckpt/new_segnet_joint/model-99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init with stored values from /root/ckpt/new_segnet_joint/model-99\n",
      "INFO:tensorflow:Restoring parameters from /root/ckpt/recg_new_five_datasets/model-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /root/ckpt/recg_new_five_datasets/model-31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init with stored values from /root/ckpt/recg_new_five_datasets/model-31\n"
     ]
    }
   ],
   "source": [
    "model_recg = Model(args, charList=open(join(args.ckptpath_recg, 'charList.txt')).read(), loss_beta=0.6,loss_weight=[.5,.5], decoderType=DecoderType.BeamSearch,experiment=experiment,mustRestore_seg=True,mustRestore_recg=True, joint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GGG\n",
      "[None, 32, 128, 1]\n",
      "0 conv1: (?, ?, ?, 32)\n",
      "0 conv2: (?, ?, ?, 32)\n",
      "1 conv1: (?, ?, ?, 64)\n",
      "1 conv2: (?, ?, ?, 64)\n",
      "2 conv1: (?, ?, ?, 128)\n",
      "2 conv2: (?, ?, ?, 128)\n",
      "1 h_deconv: (?, ?, ?, 64)\n",
      "1 h_deconv_concat: (?, ?, ?, ?)\n",
      "1 h_conv1_post_deconv: (?, ?, ?, 64)\n",
      "1 h_conv2_post_deconv: (?, ?, ?, 64)\n",
      "0 h_deconv: (?, ?, ?, 32)\n",
      "0 h_deconv_concat: (?, ?, ?, ?)\n",
      "0 h_conv1_post_deconv: (?, ?, ?, 32)\n",
      "0 h_conv2_post_deconv: (?, ?, ?, 32)\n",
      "0 outmap: (?, ?, ?, 2)\n",
      "(?, ?, ?, 2)\n",
      "loss_seg: ()\n",
      "clean output from seg: (?, 32, 128)\n",
      "recg input: (?, 128, 32)\n",
      "shape of cnn input: [None, 128, 32]\n",
      "Build Densenet4htr model with 5 blocks, 9 bottleneck layers and 9 composite layers each.\n",
      "Depth: 96\n",
      "Reduction at transition layers: 0.4\n",
      "densenet feature extractor graph built in (sec): 6.438910722732544\n",
      "Total training params: 1.0M\n",
      "shape of cnn output: [None, 32, 1, 178]\n",
      "Tensor(\"add:0\", shape=(), dtype=float32)\n",
      "INFO:tensorflow:Summary name graph_segmentation/loss/cross_entropy (raw) is illegal; using graph_segmentation/loss/cross_entropy__raw_ instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name graph_segmentation/loss/cross_entropy (raw) is illegal; using graph_segmentation/loss/cross_entropy__raw_ instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name add (raw) is illegal; using add__raw_ instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name add (raw) is illegal; using add__raw_ instead.\n",
      "COMET ERROR: Failed to extract parameters from Estimator.init()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toto_loss_shape: Tensor(\"add:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET ERROR: Failed to extract parameters from Estimator.init()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "Tensorflow: 1.12.0-rc0\n",
      "Ran global_variables_initializer first\n",
      "INFO:tensorflow:Restoring parameters from /root/ckpt/new_segnet_joint/model-99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /root/ckpt/new_segnet_joint/model-99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init with stored values from /root/ckpt/new_segnet_joint/model-99\n",
      "INFO:tensorflow:Restoring parameters from /root/ckpt/recg_new_five_datasets/model-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /root/ckpt/recg_new_five_datasets/model-31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init with stored values from /root/ckpt/recg_new_five_datasets/model-31\n"
     ]
    }
   ],
   "source": [
    "model_joint = Model(args, charList=open(join(args.ckptpath_recg, 'charList.txt')).read(), loss_beta=0.5,loss_weight=[0.95,0.05], decoderType=DecoderType.BeamSearch,experiment=experiment,mustRestore_seg=True,mustRestore_recg=True,joint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
